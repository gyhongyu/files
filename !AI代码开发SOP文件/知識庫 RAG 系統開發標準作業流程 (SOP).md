# **知識庫 RAG 系統開發標準作業流程 (SOP)**

### **文件目的**

本文件旨在為開發團隊提供一套標準化的作業流程，用於建構基於檢索增強生成 (RAG) 技術的知識庫系統。遵循此流程將確保資料處理的一致性、檢索的準確性以及生成答案的可靠性。

### **核心架構總覽**

本系統分為兩大核心階段：**「階段一：離線資料準備」** 與 **「階段二：線上即時查詢」**。

graph TD  
    subgraph 階段一：離線資料準備 (Offline Processing)  
        A\[1.1 原始檔案\<br\>(URL, PDF, DOCX, XLSX)\] \--\>|LLM 優化轉換| B(1.2 黃金資料源\<br\>Markdown 檔案)  
        B \--\>|智能分塊| C{1.3 結構化文本塊\<br\>(Chunks)}  
        C \--\>|gemini-embedding-001| D\[1.4 向量數據\]  
        D \--\>|連同元數據儲存| E\[(1.5 向量資料庫\<br\>Vector DB)\]  
        C \--\>|儲存原文| F\[(1.6 原文資料庫\<br\>Document Store)\]  
    end

    subgraph 階段二：線上即時查詢 (Online Processing)  
        G\[2.1 使用者問題\] \--\>|gemini-embedding-001| H\[2.2 問題向量\]  
        H \--\>|相似度搜索| E  
        E \--\>|返回 Top-K 元數據| I{2.3 檢索相關文本塊}  
        I \--\>|根據元數據提取| F  
        F \--\>|提供上下文| J\[2.4 構建 Prompt\]  
        G \--\>|原始問題| J  
        J \--\>|傳送給 LLM\<br\>(e.g., Gemini Pro)| K\[2.5 生成最終答案\]  
    end

    style F fill:\#f9f,stroke:\#333,stroke-width:2px  
    style B fill:\#f9f,stroke:\#333,stroke-width:2px

## **1\. 階段一：資料準備與索引 (離線處理)**

此階段為一次性或定期執行的批次處理任務，目標是建立可供檢索的知識索引。

### **1.1 來源資料轉換 (Source Data Transformation)**

* **目標**：將所有非結構化或半結構化的原始檔案 (如 **URL**、PDF、DOCX、XLSX)，轉換為統一、乾淨、結構化的 **Markdown (.md) 格式**。  
* **執行者**：自動化腳本 (Script)。  
* **工具**：  
  * **主要工具**：大型語言模型 (LLM) API，用於理解內容並進行高品質的格式轉換與摘要。  
  * **輔助工具**：  
    * **URL 處理 (標準健壯方案)**：**Puppeteer** 搭配 **turndown**。此方案能處理包括動態單頁應用程式 (SPA) 在內的所有類型網頁。  
      * **原理**：Puppeteer 是一個無頭瀏覽器 (Headless Browser)，它能像真實使用者一樣，在背景完整執行頁面上的 JavaScript，等待所有動態內容載入並渲染完成。  
      * **工作流程**：  
        1. **啟動瀏覽器**：使用 Puppeteer 啟動一個背景執行的 Chrome 瀏覽器實例。  
        2. **導航與等待**：腳本導航至目標 URL，並**等待**關鍵內容元素出現 (例如 waitForSelector('article')) 或等待網路活動靜止，確保頁面完全渲染。  
        3. **提取渲染後 HTML**：從頁面中獲取最終的、包含所有動態內容的 HTML。可在此步驟先提取主要內容區塊 (\<article\>, \<main\> 等) 以去除噪音。  
        4. **轉換為 Markdown**：將乾淨的 HTML 字串傳遞給 turndown 進行轉換。  
    * **URL 處理 (輕量級備案)**：jsdom 搭配 turndown。此方案僅適用於已確認為**純靜態**、無複雜腳本的網站。優點是速度快、資源消耗低，但無法處理動態內容。  
    * **XLSX 處理**：sheetjs。  
    * **DOCX 處理**：mammoth。  
    * **PDF 處理**：pdf-parse (處理文字型 PDF) 或 tesseract.js (處理掃描型 PDF)。  
* **產出**：  
  * 對於檔案，產出與原始檔案同名的 .md 檔案。  
  * 對於 URL，產出以其標題或 Hash 值命名的 .md 檔案。此檔案是該 URL 內容在特定時間點的**快照 (Snapshot)**，作為後續所有處理的**黃金資料源 (Golden Source)**。  
* **規範**：  
  * 必須完整保留原始文件的層級結構（標題、列表）。  
  * 表格必須轉換為標準的 Markdown 表格語法。  
  * 移除無關內容，如頁首、頁尾、廣告、導航連結等。

### **1.2 內容智能分塊 (Intelligent Content Chunking)**

* **目標**：將單一的 Markdown 檔案切分為多個語義完整、大小適中的**文本塊 (Chunks)**。  
* **執行者**：自動化腳本。  
* **核心原則**：**避免硬性切分** (例如每 500 字元切一刀)，因為這會破壞語義完整性。  
* **策略 (按優先級)**：  
  1. **結構化切分**：按 Markdown 的標題 (\#\# H2, \#\#\# H3) 進行切分，每個標題及其下的內容作為一個 chunk。  
  2. **表格切分**：將每個完整的 Markdown 表格視為一個獨立的 chunk。  
  3. **段落切分**：按換行符 (\\n\\n) 將段落切開。  
* **產出**：一系列文本塊字串。每個 chunk 都應被賦予一個唯一的標識，並記錄其來源檔案。

### **1.3 向量化與儲存 (Vectorization & Storage)**

* **目標**：為每個文本塊生成向量索引，並建立可回溯的儲存機制。  
* **執行者**：自動化腳本。  
* **流程**：  
  1. **向量化**：遍歷所有文本塊，使用 gemini-embedding-001 模型為**每一個 chunk** 生成一個 768 維的向量。  
  2. **資料庫儲存**：在向量資料庫中，為每個向量儲存一筆紀錄，包含：  
     * **向量 (Vector)**：768 維的浮點數陣列。  
     * **元數據 (Metadata)**：一個 JSON 物件，用於回溯原文。**此為必需項**。  
       {  
         "source\_file": "年度報告\_2024.md",  
         "original\_source": "https://company.com/reports/2024.pdf", // 可選，用於追溯  
         "chunk\_id": "section\_3\_2" // 或其他唯一標識  
       }

  3. **原文儲存**：在一個常規資料庫或檔案系統中（如 Document Store），儲存所有文本塊的**原文**，並可透過 source\_file 和 chunk\_id 進行快速查找。

## **2\. 階段二：查詢與生成 (線上處理)**

此階段為使用者發起查詢時的即時處理流程。

### **2.1 使用者問題向量化 (User Query Vectorization)**

* **目標**：將使用者的自然語言問題轉換為向量。  
* **流程**：接收使用者輸入的字串，調用 gemini-embedding-001 模型生成問題向量。

### **2.2 向量檢索 (Vector Retrieval)**

* **目標**：從向量資料庫中找出與問題最相關的文本塊。  
* **流程**：  
  * 使用上一步生成的問題向量，在向量資料庫中執行相似度搜索（通常是餘弦相似度）。  
  * 獲取排名最前 Top-K (例如 K=3 或 5\) 的結果。  
  * **返回的結果是文本塊的元數據 (Metadata)**，而非向量本身。

### **2.3 上下文內容提取 (Context Retrieval)**

* **目標**：根據檢索到的元數據，獲取最相關的原始文本內容。  
* **流程**：  
  * 遍歷上一步返回的 Top-K 元數據。  
  * 根據每個元數據中的 source\_file 和 chunk\_id，從原文資料庫 (Document Store) 中提取對應的**文本塊原文**。  
  * **關鍵規範**：**必須**從處理過的 .md 黃金資料源中提取內容，**絕不能**回頭去讀取原始的 PDF 或 DOCX 檔案，以確保資料一致性。

### **2.4 增強生成 (Augmented Generation)**

* **目標**：結合上下文和使用者問題，生成準確、自然的回答。  
* **流程**：  
  1. **構建 Prompt**：創建一個結構化的 Prompt，將提取出的多個文本塊（作為上下文）和使用者的原始問題整合進去。  
  2. **調用 LLM**：將構建好的 Prompt 發送給生成式大模型（如 Gemini Pro）。  
  3. **返回答案**：將 LLM 生成的答案呈現給使用者。

## **3\. 附錄一：Prompt 範例**

一個結構良好的 Prompt 模板對於生成高品質答案至關重要。

您是一位專業的財務分析助理。請根據以下提供的上下文資料，精確地回答使用者的問題。如果上下文未提供相關資訊，請回答「根據我手邊的資料，無法回答這個問題」。請不要自行編造內容。

\---  
\#\#\# 上下文資料

\*\*資料來源 1 (年度報告\_2024.md, section\_3\_2):\*\*  
\> 在 2024 財年，本公司的總營收達到了 15.2 億美元，相較去年同期增長了 12%。其中，亞太地區的營收貢獻佔比為 40%，達到 6.08 億美元。

\*\*資料來源 2 (年度報告\_2024.md, section\_4\_1):\*\*  
\> 公司的研發投入持續增加，本財年投入 2.1 億美元用於新產品線的開發，主要集中在 AI 雲端服務領域。

\---  
\#\#\# 使用者問題  
公司在 2024 財年的總營收是多少？亞太地區的貢獻有多少？

## **4\. 附錄二：從本地到企業級的架構演進**

本 SOP 文件提供了一套在本地或自架設環境中，實現高效能 RAG 系統的標準最佳實踐。然而，在與如 Google NotebookLM 等雲端原生服務比較時，開發者可能會觀察到顯著的速度差異。本章節旨在闡明這些差異的來源，並提供從本地開發到企業級部署的架構演進路徑。

### **本地實現 vs. 企業級實現**

您的自建系統與企業級服務在**架構思想上是一致的**，核心差異在於**工程化水平與基礎設施**。

* **本地實現 (本 SOP)**  
  * **核心優勢**: 成本可控、資料私有、易於客製化。  
  * **效能瓶頸**:  
    * **循序處理 (Sequential Processing)**: 檔案轉換與向量化通常是逐一處理，難以應對大量資料的同時湧入。  
    * **通用硬體 (General Hardware)**: 在標準 CPU/GPU 上運行，未針對大規模 AI 運算進行特別優化。  
    * **開源元件 (Open-Source Components)**: 本地的向量資料庫在處理百萬級以上的向量時，檢索延遲會顯著增加。  
* **企業級實現 (如 NotebookLM)**  
  * **核心優勢**: 極致的速度、高擴展性、高可用性。  
  * **速度來源**:  
    * **大規模平行運算 (Massive Parallelism)**: 透過雲端函式 (Cloud Functions) 等無伺服器架構，每個檔案的處理都可觸發一個獨立的運算實例，實現成千上萬個任務的同時處理。  
    * **專用硬體 (Specialized Hardware)**: 在 Google Cloud 內部，Embedding 等 AI 運算運行於專為矩陣運算設計的 TPU (Tensor Processing Units) 上，速度遠超通用硬體。  
    * **託管雲端服務 (Managed Cloud Services)**: 使用如 Vertex AI Vector Search 這類專為數十億級向量設計的託管服務，能在巨大資料量下依然維持毫秒級的檢索延遲。

### **架構演進路徑建議**

1. **起步階段**: 完全遵循本 SOP，在本地或單一伺服器上建立功能完整的 RAG 系統，驗證業務邏輯。這是最務實且成本效益最高的起點。  
2. **成長階段**: 當資料量或使用者請求增長，導致效能瓶頸出現時，逐步將瓶頸環節遷移至雲端。例如，優先將本地的向量資料庫替換為雲端託管的向量搜尋服務 (如 Vertex AI Vector Search)。  
3. **成熟階段**: 最終，可將整個離線處理流程改造成由雲端工作流 (Cloud Workflows) 編排的、事件驅動的無伺服器架構，實現與頂級服務相仿的效能與擴展性，打造真正的企業級知識庫。